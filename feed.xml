<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://lurosenb.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://lurosenb.github.io/" rel="alternate" type="text/html" hreflang="en" /><updated>2025-05-21T01:30:42+00:00</updated><id>https://lurosenb.github.io/feed.xml</id><title type="html">blank</title><subtitle>Academic site for Lucas Rosenblatt
</subtitle><entry><title type="html">Counterfactual Fairness Is Basically Demographic Parity</title><link href="https://lurosenb.github.io/blog/2023/cf-is-dp/" rel="alternate" type="text/html" title="Counterfactual Fairness Is Basically Demographic Parity" /><published>2023-05-15T21:01:00+00:00</published><updated>2023-05-15T21:01:00+00:00</updated><id>https://lurosenb.github.io/blog/2023/cf-is-dp</id><content type="html" xml:base="https://lurosenb.github.io/blog/2023/cf-is-dp/"><![CDATA[<h2 id="counterfactual-fairness-is-basically-demographic-parity">Counterfactual Fairness Is Basically Demographic Parity</h2>
<p>I find that most research papers could use an accompanying translation into plain English. <strong>So, here’s my attempt at that for our paper on counterfactual fairness!</strong> The original paper lives <a href="https://arxiv.org/pdf/2208.03843.pdf">here</a>, and the supporting repository lives <a href="https://github.com/lurosenb/simplifying_counterfactual_fairness">here</a>.</p>

<p>Let’s dive in.</p>

<h3 id="demographic-or-statistical-parity">Demographic or statistical parity</h3>
<p>Before we get into the meat of the paper, its important to understand two common fairness definitions. Let’s discuss <strong>demographic/statistical parity</strong> (<em>note: you will see people using both names to mean the same thing. We’ll use statistical parity from now on, sometimes abbreviated SP</em> ).</p>

<p>Statistical parity is a natural first fairness definition. Outside of the formalism, the best way to understand it is through an example. Consider the following candidate pool and accepted pool, where candidates can either be <strong>brainy smurfs</strong> or <strong>minions</strong>.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cfisdp/smurf_minion_unfair.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>

<p>In this example, we see that the candidate pool has both brainy smurfs and minions. However, <strong>the accepted pool is 100% brainy smurfs.</strong> This would be an example of a statistical parity violation. Statistical parity is violated when the acceptance rate of a privileged group (i.e. brainy smurfs) is different than the acceptance rate of an unprivileged group (minions). Conversely, <strong>if the probability of receiving a positive label for both groups is the same, then statistical parity is satisfied</strong>. Thus, the following breakdown would satisfy statistical parity:</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cfisdp/smurf_minion.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>

<p>Hopefully, now the following formalism (with annotations) will make intuitive sense!</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cfisdp/stat_parity_formal.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>

<h3 id="counterfactual-fairness">Counterfactual fairness</h3>
<p>Let’s move on to <strong>counterfactual fairness</strong>, which appears at first a more complex fairness definition that is based on the idea of counterfactuals and causal modeling. Intuitively, a counterfactual is a statement about <strong>what <em>would</em> have happened had something else happened</strong>. For example, were I to say “If I had studied harder, I would have gotten an A on the test,” I would be making a counterfactual statement.</p>

<p>We won’t go into all of the details of causal modeling here. For a great explanation of the nuances of causal modeling and counterfactuals in particular, see this <a href="https://www.inference.vc/causal-inference-3-counterfactuals/">excellent blog series</a> by Ferenc Huszár.</p>

<p>Instead, we will only discuss the relevant concepts to this work, again using the examples of smurfs and minions. Consider the following extremely simple <strong><em>structural causal model</em> (SCM)</strong> in the smurf context:</p>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cfisdp/causal_smurf.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>

<p>Whether a candidate gets accepted or not hinges on two factors - first, if the candidate belongs to the intellectually gifted group of brainy smurfs, and second, a <em>latent</em> variable known as “worthiness.”</p>

<details>
<summary>
What's a latent variable?
</summary>
A "latent variable" is just a fancy name for a variable that we did not measure (i.e. we have no data on) but instead postulate as affecting our system. Using our SCM, we can infer a value for our latent variable by leveraging a mathematical model relating other variables that we did observe to our latent variable. There are many ways to do this! We do it like this, see<a href="https://github.com/lurosenb/simplifying_counterfactual_fairness/blob/main/Simplifying_Counterfactual_Fairness.ipynb"> full implementation for all details </a>:


<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">inferU</span><span class="p">(</span><span class="n">GroundTruthModel</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">latent</span><span class="o">=</span><span class="sh">'</span><span class="s">K</span><span class="sh">'</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nf">copy</span><span class="p">().</span><span class="nf">reset_index</span><span class="p">()</span>
        <span class="c1"># hold all K values
</span>        <span class="n">U</span><span class="o">=</span><span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">data</span><span class="p">)):</span>
                <span class="n">dictionary</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span><span class="mi">0</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">X</span><span class="p">}</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">X</span><span class="p">:</span> <span class="n">dictionary</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">i</span><span class="p">])</span>
                <span class="n">conditioned</span> <span class="o">=</span> <span class="n">pyro</span><span class="p">.</span><span class="nf">condition</span><span class="p">(</span><span class="n">GroundTruthModel</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">dictionary</span><span class="p">)</span>
                <span class="c1"># use pyro.infer.Importance
</span>                <span class="n">posterior</span> <span class="o">=</span> <span class="n">pyro</span><span class="p">.</span><span class="n">infer</span><span class="p">.</span><span class="nc">Importance</span><span class="p">(</span><span class="n">conditioned</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">).</span><span class="nf">run</span><span class="p">()</span>
                <span class="n">post_marginal</span> <span class="o">=</span> <span class="n">pyro</span><span class="p">.</span><span class="n">infer</span><span class="p">.</span><span class="nc">EmpiricalMarginal</span><span class="p">(</span><span class="n">posterior</span><span class="p">,</span> <span class="n">latent</span><span class="p">)</span>
                <span class="n">post_samples</span> <span class="o">=</span> <span class="p">[</span><span class="nf">post_marginal</span><span class="p">().</span><span class="nf">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
                <span class="c1"># calculate the mean of the inferred
</span>                <span class="n">U</span> <span class="o">+=</span> <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">post_samples</span><span class="p">)]</span>
        <span class="k">return</span> <span class="n">U</span></code></pre></figure>


</details>

<p>The arrows provide the causal relationships. So, in our model, <strong>Smurf?</strong> causally influences <strong>Accepted</strong>, as does <strong>Worthiness</strong>.</p>

<p>At this point, some of you might be scratching your heads and asking, <strong>“What about the connection between **Smurf?</strong> and <strong>Worthiness</strong>?” Well, in our model, there isn’t one!** A candidates <strong>Smurf?</strong>-ness and their <strong>Worthiness</strong> are independent of each other. In our paper, we denote this requirement as <strong>Criteria 3</strong>. But why is this a criteria?</p>

<p>Well, as you are hopefully beginning to understand, counterfactual fairness attempts to explain behavior from protected attributes and latent variables. The protected attributes could hold information on features outside of individuals’ control which would very often be unfair to base decisions on, while the latent variables contain information on features within an individual’s control which are fair to base decisions on. <strong>From this perspective, it is clear that in many contexts the latent variables must be independent of protected attributes.</strong> Otherwise, this would imply that, for example, the inherent ‘worthiness’ of latent variables could problematically depend on a protected attribute.</p>

<h3 id="doing-a-counterfactual">Doing a counterfactual</h3>

<p>So, what happens if we shake things up a bit? What if we magically turned a Minion into a Brainy Smurf? This is where Judea Pearl’s “do” calculus comes in. <strong>Pearl’s “do” operator (think of it as a magic wand) lets us tweak one variable in our model and see how that changes the outcome.</strong></p>

<p>With our magic wand, we could ask, “What’s the likelihood of a candidate getting accepted if we transform them into a Brainy Smurf?” This is represented as:</p>

\[P(Acceptance = yes~|~do(Species = Brainy Smurf))\]

<p>or as</p>

\[P(Acceptance_{Species \leftarrow Brainy Smurf} = yes)\]

<p>In other words, this tells us the probability of acceptance when we intervene and set the ‘Species’ variable to Brainy Smurf, bypassing the natural course of the universe.</p>

<p>This brings us to the heart of counterfactual fairness. Let’s say a Minion was accepted. Now we can ask a counterfactual question: “What if that Minion had been a Brainy Smurf? Would they still have been accepted?” By considering both our structural model and this observed data, we can dive into these alternative realities, enabling a fair comparison across different groups.</p>

<p>In essence, counterfactual fairness allows us to imagine an equal playing field, providing a lens to understand and measure fairness in our decisions. It challenges us to ask, “What would have happened if things were different?”, ultimately pushing us to build more just and equitable systems.</p>

<p>Formally, we say something like this:</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/cfisdp/cf_formal.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>

<h3 id="so-counterfactual-fairness-is-basically-statistical-parity">So, counterfactual fairness is basically statistical parity?</h3>
<p>How do we go about seeing this? The derivation is subtle, but short, so I’ll include it here for those who are interested.</p>

<p>Remember Criteria 3, it’ll come in handy in the following derivation!</p>

<p>Note that a predictor which satisfies counterfactual fairness must have an internal method of estimating latent variables and a causal model. So to say that a predictor which satisfies demographic parity also satisfies counterfactual fairness, we must introduce such a method and causal model. We do so in the proof of the first theorem in a trivial way.</p>

<details>
<summary>
<b>Theorem</b>: Any predictor $\hat{Y}': X \times A \rightarrow Y$ that satisfies demographic parity can be modified into a method for estimating latent variables and a predictor $\hat{Y}: U \times A \rightarrow Y$ that is counterfactually fair.
</summary>
<b>Proof</b>: Our estimate of the latent variables $u$, given protected attributes $a$ and remaining attributes $x$, is $u = \hat{Y}'(x, a)$. Then the predictor $\hat{Y}: U \times A \rightarrow Y$ is given by the identity function $\hat{Y}_{A \gets a}(u) = u$. Because $\hat{Y}'$ satisfies demographic parity, we know $\Pr(u |a) = \Pr(u | a')$ for $a, a' \in A$. That is, latent variables are independent of protected attributes which meets Criteria 3. Further, $\hat{Y}$ satisfies counterfactual fairness because $\hat{Y}_{A \gets a}(u) = u = \hat{Y}_{A \gets a'}(u)$.
</details>

<p>Next we prove the converse so that we can make such a bold claim; namely, that any counterfactually fair predictor also satisfies demographic parity.</p>

<details>
<summary>
<b>Theorem</b>: Consider a method for estimating latent variables and a counterfactually fair predictor $\hat{Y}:U \times X \rightarrow Y$. Then the resulting predictor  $\hat{Y'}: X \times A \rightarrow Y$ satisfies demographic parity.
</summary>
<b>Proof</b>: 
Since the predictor is counterfactually fair,
    we know 
    \begin{align}\label{eq:cf}
       \Pr(\hat{Y}_{A \gets a}(u)=y|x, a)
        =\Pr(\hat{Y}_{A \gets a'}(u)=y|x, a) 
    \end{align}    
    for all $y \in Y$ where the realization
    of latent variables
    $u \in U$ is estimated from observations
    $a \in A$ and $x \in X$.
    Taking a weighted sum (if $X$ contains
    continuous random variables, an analogous statement
    holds via integration) of the right side of
    Equation (\ref{eq:cf}) yields
    \begin{align*}
        &amp;\sum_{x \in X} \Pr(x | a)
        \Pr(\hat{Y}_{A \gets a}(u)=y|x, a) \\
        &amp;= \sum_{x \in X} \Pr
        (x, \hat{Y}_{A \gets a}(u)=y|a) \\
        &amp;= \Pr(\hat{Y}_{A \gets a}(u)=y|a)
        = \Pr(\hat{Y}_{A \gets a}(u)=y).
    \end{align*}
    The first equality holds because
    $\Pr(x|a) \Pr(y|x,a) = \Pr(x,y|a)$
    for random events $x,y,a$.
    The last equality holds by Criteria 3 and since the
    (possible) randomness of $\hat{Y}_{A \gets a}(u)$
    only comes from $u$ and the assignment $A \gets a$.
    The final equality gets us close to demographic parity
    but the predictions could still depend on the
    assignment.
    We repeat the same steps for the
    left side of Equation (\ref{eq:cf})
    and find that
    \begin{align*}
        \Pr(\hat{Y}_{A \gets a}(u) = y)
        = \Pr(\hat{Y}_{A \gets a'}(u) = y).
    \end{align*}
    This tells us that the distribution of
    predictions made by a counterfactually fair
    algorithm are independent of protected
    attributes. That is, demographic parity holds.
</details>

<h3 id="intuition-and-experiments">Intuition and experiments</h3>]]></content><author><name>Lucas Rosenblatt</name></author><category term="research" /><category term="research" /><summary type="html"><![CDATA[So be careful which one you use!]]></summary></entry><entry><title type="html">The school bus</title><link href="https://lurosenb.github.io/blog/2021/bus/" rel="alternate" type="text/html" title="The school bus" /><published>2021-05-15T21:01:00+00:00</published><updated>2021-05-15T21:01:00+00:00</updated><id>https://lurosenb.github.io/blog/2021/bus</id><content type="html" xml:base="https://lurosenb.github.io/blog/2021/bus/"><![CDATA[<h3 id="making-max-school-bus-to-sustainable-mobile-home">Making Max: School Bus to Sustainable Mobile Home</h3>
<p>With my amazing partner Ellie, I have been converting a 2006 International School Bus (33 feet long) into a mobile, sustainable home for the past few years. Check out some of the awesome social media Ellie has put together <a href="https://www.youtube.com/channel/UC88iA7BSMY1sMTs9KUB_lvw">here</a> and <a href="">here</a>, and some photos I’ve included here. If you’re curious about any project details, from kitchen to wood stove to solar panels, ask me! It’s fun to talk about.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/schoolbus/bus1.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/schoolbus/bus2.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/schoolbus/bus3.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/schoolbus/bus4.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/schoolbus/bus5.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/schoolbus/bus6.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/schoolbus/bus7.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/schoolbus/bus8.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/schoolbus/bus9.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/schoolbus/bus10.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/schoolbus/bus11.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>]]></content><author><name></name></author><category term="bus" /><category term="bus" /><summary type="html"><![CDATA[A brief tour of our skoolie conversion.]]></summary></entry></feed>